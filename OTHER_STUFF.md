![YouTube logo](yt.png)
[A Hackers' Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU) -
**Jeremy Howard**

![YouTube logo](yt.png)
[The End of Finetuning](https://www.youtube.com/watch?v=5Sze3kHAZqE) -
**Jeremy Howard** - domain FT and instruction FT;
the single-shot memorization phenomenon;
catastrophic forgetting;
RAG is such an inefficient hack;
GPT-4 with good prompting plays good chess.

![YouTube logo](yt.png)
[Open Questions for AI Engineering](https://www.youtube.com/watch?v=qw4PrtyvJI0&t=24953s) -
**Simon Willison**

> ChatGPT has no affordances.

> People decided it was hype because they dived in and asked it for arithmetic and facts!

> Moving beyond a chat interface.

[Finetuned language models are zero-shot learners](https://openreview.net/pdf?id=gEZrGCozdqR)

> In this paper, we explore a simple method to improve the zero-shot performance of large language
models, which would expand their reach to a broader audience.

> The idea is that by using supervision to teach an LM to perform tasks described via
instructions, the LM will learn to follow instructions and do so even for unseen tasks.

It doesn't explain what the training is :(
