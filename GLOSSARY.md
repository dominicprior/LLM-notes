**logit** [ðŸ”—](https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow)

1. a scalar inside a neural net.

2. (more specifically) an element of the raw (non-normalized) array of predictions that are
then passed to the softmax function.  i.e. the
negative log probability (which also matches the typical LLM loss function).


**activation** [ðŸ”—](https://stats.stackexchange.com/questions/333700/to-what-exactly-does-the-term-activations-refer-in-neural-networks)

1. a function like ReLU.

2. an output value of an activation function, i.e. the value of a neuron.

**In-context learning**
[ðŸ”—](https://www.hopsworks.ai/dictionary/in-context-learning-icl#:~:text=In%2Dcontext%20learning%20(ICL),the%20need%20for%20fine%2Dtuning.)
1. a specific method of prompt engineering where demonstrations of the task are provided to the model as part of the prompt
