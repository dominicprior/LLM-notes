**logit** - (1) a scalar inside a neural net; or more specifically,
(2), an element of the raw (non-normalized) array of predictions that are
then passed to the softmax function.  In other words, a logit is the
negative log probability (which also matches the typical LLM loss function).
[ðŸ”—](https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow)

**activation** - (1) a function like ReLU; (2) an output value of an activation function,
the value of a neuron.
[ðŸ”—](https://stats.stackexchange.com/questions/333700/to-what-exactly-does-the-term-activations-refer-in-neural-networks)
