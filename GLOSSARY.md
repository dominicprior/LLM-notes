**logit** [ðŸ”—](https://stackoverflow.com/questions/41455101/what-is-the-meaning-of-the-word-logits-in-tensorflow)

1. a scalar inside a neural net.

2. (more specifically) an element of the raw (non-normalized) array of predictions that are
then passed to the softmax function.  i.e. the
negative log probability (which also matches the typical LLM loss function).


**activation** [ðŸ”—](https://stats.stackexchange.com/questions/333700/to-what-exactly-does-the-term-activations-refer-in-neural-networks)

1. a function like ReLU.

2. an output value of an activation function, i.e. the value of a neuron.

