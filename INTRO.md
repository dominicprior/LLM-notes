# Intro

From writing poetry to giving medical advice, [large language models](https://en.wikipedia.org/wiki/Large_language_model) are shockingly general, giving us a first hint of the G in [artificial general intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence).  They are also [surprisingly simple](https://dugas.ch/artificial_curiosity/GPT_architecture.html), and yet, due to their [immense size](https://github.com/amirgholami/ai_and_memory_wall#nlp-models), are deeply inscrutable, despite [some](https://arxiv.org/abs/2211.00593) [heroic](https://arxiv.org/abs/2012.14913) [efforts](https://arxiv.org/abs/2305.16130).

# Timeline

[GPT-2](https://en.wikipedia.org/wiki/GPT-2), [GPT-3](https://en.wikipedia.org/wiki/GPT-3), 

# Weaknesses

As [Dan Piponi](https://mathstodon.xyz/@dpiponi/111116694861297725) noted:

> And yet I think more has been written about what ChatGPT can't do than has been written about what any other tool can't do. It's all very strange.

The biggest weakness is their complete inability to tell if they are [telling the truth](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)).

# Scale

The GPT-3 paper has this:

![Screenshot of a table of model sizes.](model_sizes.png)
